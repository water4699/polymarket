# PredictLab æ•°æ®å®Œæ•´æ€§å’Œæ ¡éªŒæœºåˆ¶

## ğŸ“‹ æ¦‚è¿°

PredictLab æ•°æ®å®Œæ•´æ€§å’Œæ ¡éªŒæœºåˆ¶æä¾›ä»æ•°æ®é‡‡é›†åˆ°æœ€ç»ˆåˆ†æçš„ç«¯åˆ°ç«¯è´¨é‡ä¿éšœã€‚é€šè¿‡å¤šå±‚æ¬¡æ ¡éªŒã€å¢é‡ä¸€è‡´æ€§ä¿è¯å’Œå®æ—¶ç›‘æ§ï¼Œç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œå¯é æ€§ã€‚

## ğŸ—ï¸ æ ¡éªŒæ¶æ„

### ä¸‰å±‚æ ¡éªŒä½“ç³»

#### ğŸ—ƒï¸ Raw Layer æ ¡éªŒ
**æ ¡éªŒå†…å®¹**:
- æ•°æ®å­˜åœ¨æ€§æ£€æŸ¥
- æ•°æ®æ ¼å¼éªŒè¯
- å¿…éœ€å­—æ®µå®Œæ•´æ€§
- æ—¶é—´æˆ³æœ‰æ•ˆæ€§
- æ•°æ®å“ˆå¸Œä¸€è‡´æ€§

**æ ¡éªŒè§„åˆ™ç¤ºä¾‹**:
```python
# Rawæ•°æ®å­˜åœ¨æ€§
if df.empty:
    raise ValidationError("Rawæ•°æ®ä¸ºç©º")

# æ—¶é—´æˆ³æœ‰æ•ˆæ€§
invalid_timestamps = df['timestamp'].isna().sum()
if invalid_timestamps > 0:
    log.warning(f"å‘ç°{invalid_timestamps}ä¸ªæ— æ•ˆæ—¶é—´æˆ³")
```

#### ğŸ§¹ Clean Layer æ ¡éªŒ
**æ ¡éªŒå†…å®¹**:
- æ•°æ®å®Œæ•´æ€§ (ç¼ºå¤±å€¼æ£€æµ‹)
- æ•°æ®å”¯ä¸€æ€§ (é‡å¤æ•°æ®æ£€æµ‹)
- æ—¶é—´åºåˆ—è¿ç»­æ€§
- æ•°å€¼åˆç†æ€§ (å¼‚å¸¸å€¼æ£€æµ‹)
- ä¸šåŠ¡é€»è¾‘ä¸€è‡´æ€§ (OHLCé€»è¾‘)

**æ ¡éªŒè§„åˆ™ç¤ºä¾‹**:
```python
# ç¼ºå¤±å€¼æ£€æµ‹
missing_values = df.isnull().sum()
if missing_values.any():
    log.warning(f"å‘ç°ç¼ºå¤±å€¼: {missing_values[missing_values > 0]}")

# OHLCé€»è¾‘æ ¡éªŒ
ohlc_valid = (
    (df['high'] >= df['open']) &
    (df['high'] >= df['close']) &
    (df['low'] <= df['open']) &
    (df['low'] <= df['close'])
)
invalid_count = (~ohlc_valid).sum()
```

#### ğŸ¯ Feature Layer æ ¡éªŒ
**æ ¡éªŒå†…å®¹**:
- æŠ€æœ¯æŒ‡æ ‡å®Œæ•´æ€§
- æŒ‡æ ‡æ•°å€¼åˆç†æ€§
- è®¡ç®—ä¸€è‡´æ€§éªŒè¯
- æ—¶é—´åºåˆ—è¿ç»­æ€§

**æ ¡éªŒè§„åˆ™ç¤ºä¾‹**:
```python
# RSIèŒƒå›´æ ¡éªŒ
invalid_rsi = ((df['rsi_14'] < 0) | (df['rsi_14'] > 100)).sum()
if invalid_rsi > 0:
    log.error(f"RSIå€¼è¶…å‡ºåˆç†èŒƒå›´: {invalid_rsi}æ¡è®°å½•")

# ç§»åŠ¨å¹³å‡çº¿åˆç†æ€§
ma_negative = (df['sma_20'] < 0).sum()
if ma_negative > 0:
    log.error(f"ç§»åŠ¨å¹³å‡çº¿å‡ºç°è´Ÿå€¼: {ma_negative}æ¡è®°å½•")
```

## âš™ï¸ æ ¸å¿ƒåŠŸèƒ½

### æ•°æ®æ ¡éªŒå™¨ (`data_validator.py`)

#### ä¸»è¦æ–¹æ³•
```python
# Rawæ•°æ®æ ¡éªŒ
report = data_validator.validate_raw_data(data, source_type, ValidationLevel.STANDARD)

# Cleanæ•°æ®æ ¡éªŒ
report = data_validator.validate_clean_data(df, source_type, symbol, ValidationLevel.STRICT)

# Featureæ•°æ®æ ¡éªŒ
report = data_validator.validate_feature_data(df, symbol, interval_type, ValidationLevel.STANDARD)

# å¢é‡æ›´æ–°æ ¡éªŒ
report = data_validator.validate_incremental_update(existing_data, new_data, symbol, data_type)
```

#### æ ¡éªŒçº§åˆ«
- **BASIC**: åŸºç¡€æ ¡éªŒï¼ˆå­˜åœ¨æ€§ã€æ ¼å¼ï¼‰
- **STANDARD**: æ ‡å‡†æ ¡éªŒï¼ˆå®Œæ•´æ€§ã€ä¸€è‡´æ€§ï¼‰
- **STRICT**: ä¸¥æ ¼æ ¡éªŒï¼ˆä¸šåŠ¡è§„åˆ™ã€è´¨é‡æ ‡å‡†ï¼‰
- **COMPREHENSIVE**: å…¨é¢æ ¡éªŒï¼ˆæ‰€æœ‰è§„åˆ™ï¼‰

### è´¨é‡ç›‘æ§å™¨ (`quality_monitor.py`)

#### ç›‘æ§æŒ‡æ ‡
```python
# Rawæ•°æ®è´¨é‡
"raw_completeness": "Rawæ•°æ®å®Œæ•´æ€§"
"raw_accuracy": "Rawæ•°æ®å‡†ç¡®æ€§"
"raw_timeliness": "Rawæ•°æ®åŠæ—¶æ€§"

# Cleanæ•°æ®è´¨é‡
"clean_completeness": "Cleanæ•°æ®å®Œæ•´æ€§"
"clean_uniqueness": "Cleanæ•°æ®å”¯ä¸€æ€§"
"clean_consistency": "Cleanæ•°æ®ä¸€è‡´æ€§"

# Featureæ•°æ®è´¨é‡
"feature_completeness": "Featureæ•°æ®å®Œæ•´æ€§"
"feature_accuracy": "Featureæ•°æ®å‡†ç¡®æ€§"

# ç³»ç»Ÿçº§æŒ‡æ ‡
"pipeline_success_rate": "ç®¡é“æˆåŠŸç‡"
"data_freshness": "æ•°æ®æ–°é²œåº¦"
```

#### å‘Šè­¦ç³»ç»Ÿ
```python
# å‘Šè­¦çº§åˆ«
alert.level in ["warning", "error", "critical"]

# å‘Šè­¦ç¤ºä¾‹
QualityAlert(
    alert_id="raw_completeness_001",
    metric_id="raw_completeness",
    level="warning",
    message="Rawæ•°æ®å®Œæ•´æ€§ä½äºé˜ˆå€¼: 94.2% < 95.0%",
    details={"current_score": 94.2, "threshold": 95.0}
)
```

## ğŸ”„ å¢é‡æ›´æ–°ä¸€è‡´æ€§ä¿è¯

### å¢é‡æ ¡éªŒæœºåˆ¶

#### 1. æ•°æ®å†²çªæ£€æµ‹
```python
# æ—¶é—´æˆ³å†²çªæ£€æŸ¥
existing_times = set(existing_data['timestamp'])
new_times = set(new_data['timestamp'])
conflicts = existing_times & new_times

if conflicts:
    log.warning(f"å‘ç°{len(conflicts)}ä¸ªæ—¶é—´æˆ³å†²çª")
```

#### 2. æ•°æ®è¿ç»­æ€§éªŒè¯
```python
# æ£€æŸ¥å¢é‡æ›´æ–°åçš„æ—¶é—´è¿ç»­æ€§
combined_data = pd.concat([existing_data, new_data])
timestamps = combined_data['timestamp'].sort_values()
gaps = timestamps.diff().dropna()

# æ£€æµ‹å¼‚å¸¸é—´éš”
median_gap = gaps.median()
abnormal_gaps = gaps > (median_gap * 5)
```

#### 3. æ•°å€¼åˆç†æ€§æ£€æŸ¥
```python
# å¢é‡æ•°æ®ä¸å†å²æ•°æ®çš„æ•°å€¼åˆ†å¸ƒæ¯”è¾ƒ
existing_prices = existing_data['price']
new_prices = new_data['price']

# Z-scoreå¼‚å¸¸æ£€æµ‹
combined_prices = pd.concat([existing_prices, new_prices])
z_scores = (new_prices - combined_prices.mean()) / combined_prices.std()
outliers = (z_scores.abs() > 3).sum()
```

### å†å²é‡ç®—ä¸€è‡´æ€§

#### ç‰ˆæœ¬æ§åˆ¶
```python
# æŒ‡æ ‡é‡ç®—ç‰ˆæœ¬ç®¡ç†
indicators_data['calculation_version'] = 'v1.2'
indicators_data['recalculation_timestamp'] = datetime.now()

# å†å²ç‰ˆæœ¬æ¯”è¾ƒ
old_indicators = get_historical_indicators(symbol, interval, 'v1.1')
new_indicators = recalculate_indicators(symbol, interval)

# å·®å¼‚åˆ†æ
differences = compare_indicator_versions(old_indicators, new_indicators)
```

#### æ•°æ®éš”ç¦»
```python
# é‡ç®—æ—¶ä½¿ç”¨æ•°æ®å¿«ç…§
with transaction():
    # åˆ›å»ºä¸´æ—¶è¡¨å­˜å‚¨é‡ç®—ç»“æœ
    temp_table = create_temp_indicator_table()

    # é‡ç®—æŒ‡æ ‡
    recalculated_data = perform_recalculation(base_data)

    # æ ¡éªŒé‡ç®—ç»“æœ
    validation_report = validate_recalculation_consistency(
        original_data, recalculated_data
    )

    if validation_report.is_pass:
        # æ›¿æ¢åŸæ•°æ®
        replace_original_indicators(recalculated_data)
    else:
        # å›æ»šé‡ç®—
        rollback_recalculation()
        log.error("é‡ç®—ç»“æœæ ¡éªŒå¤±è´¥ï¼Œå·²å›æ»š")
```

## ğŸ“Š æŠ¥å‘Šå’Œç›‘æ§

### æ ¡éªŒæŠ¥å‘Šæ ¼å¼

#### JSONæŠ¥å‘Š
```json
{
  "data_type": "clean",
  "symbol": "BTC_PRICE",
  "validation_level": "standard",
  "total_records": 1000,
  "quality_score": 96.5,
  "is_pass": true,
  "issues": [
    {
      "rule_id": "clean_data_completeness",
      "level": "warning",
      "result": "warning",
      "message": "å‘ç°3ä¸ªç¼ºå¤±å€¼",
      "affected_records": 3
    }
  ]
}
```

#### HTMLä»ªè¡¨æ¿
```html
<!DOCTYPE html>
<html>
<head>
    <title>PredictLab æ•°æ®è´¨é‡ä»ªè¡¨æ¿</title>
    <style>
        .metric { display: inline-block; margin: 10px; padding: 20px; border: 1px solid #ddd; }
        .alert { background: #ffebee; border-left: 4px solid #f44336; margin: 10px 0; padding: 10px; }
        .score { font-size: 24px; font-weight: bold; }
    </style>
</head>
<body>
    <h1>PredictLab æ•°æ®è´¨é‡ä»ªè¡¨æ¿</h1>
    <div class="metric">
        <h3>æ€»ä½“è¯„åˆ†</h3>
        <div class="score">96.5</div>
    </div>
</body>
</html>
```

### ç›‘æ§å‘Šè­¦

#### å®æ—¶ç›‘æ§
```python
# å¯åŠ¨è´¨é‡ç›‘æ§
await quality_monitor.start_monitoring(interval_minutes=60)

# è·å–å½“å‰çŠ¶æ€
active_alerts = quality_monitor.get_active_alerts()
current_metrics = await quality_monitor.run_quality_check()
```

#### å‘Šè­¦å¤„ç†
```python
# è§£å†³å‘Šè­¦
quality_monitor.resolve_alert(alert_id)

# è·å–å‘Šè­¦å†å²
alert_history = quality_monitor.get_alert_history(days=7)
```

## ğŸ”§ é›†æˆåˆ°æ•°æ®ç®¡é“

### ä»»åŠ¡è°ƒåº¦å™¨é›†æˆ

#### æ ¡éªŒä»»åŠ¡ç¤ºä¾‹
```python
# åœ¨task_scheduler.pyä¸­æ·»åŠ æ ¡éªŒä»»åŠ¡

async def _task_validate_pipeline_step(self, step_name: str, symbol: str) -> Dict[str, Any]:
    """æ ¡éªŒç®¡é“æ­¥éª¤çš„æ•°æ®è´¨é‡"""
    if step_name == "raw":
        # Rawæ•°æ®æ ¡éªŒ
        data = await self._get_raw_data(symbol)
        report = data_validator.validate_raw_data(data, 'predict', ValidationLevel.STANDARD)

    elif step_name == "clean":
        # Cleanæ•°æ®æ ¡éªŒ
        data = await self._get_clean_data(symbol)
        report = data_validator.validate_clean_data(data, 'predict', symbol, ValidationLevel.STANDARD)

    elif step_name == "feature":
        # Featureæ•°æ®æ ¡éªŒ
        data = await self._get_feature_data(symbol)
        report = data_validator.validate_feature_data(data, symbol, '1h', ValidationLevel.STANDARD)

    # è®°å½•æ ¡éªŒç»“æœ
    if not report.is_pass:
        log.warning(f"{step_name}æ•°æ®æ ¡éªŒæœªé€šè¿‡: {report.score:.1f}")
        # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–ç»ˆæ­¢ç®¡é“

    return {
        'step': step_name,
        'symbol': symbol,
        'score': report.score,
        'passed': report.is_pass,
        'issues': len(report.issues)
    }
```

### æ•°æ®ç®¡ç†å™¨é›†æˆ

#### å¢é‡æ›´æ–°å®‰å…¨æ£€æŸ¥
```python
# åœ¨data_manager.pyä¸­é›†æˆå®‰å…¨æ£€æŸ¥

async def safe_incremental_update(self, symbol: str, new_data: pd.DataFrame) -> bool:
    """å®‰å…¨å¢é‡æ›´æ–°"""
    # 1. å®‰å…¨æ£€æŸ¥
    safety_check = await self.incremental_update_safety_check(symbol, new_data)

    if not safety_check['safe_to_update']:
        log.error(f"å¢é‡æ›´æ–°å®‰å…¨æ£€æŸ¥å¤±è´¥: {safety_check['errors']}")
        return False

    if safety_check['warnings']:
        log.warning(f"å¢é‡æ›´æ–°å­˜åœ¨è­¦å‘Š: {safety_check['warnings']}")

    # 2. æ‰§è¡Œæ›´æ–°
    try:
        await self.perform_incremental_update(symbol, new_data)

        # 3. åæ ¡éªŒ
        consistency_check = await self.validate_data_consistency(symbol)
        if not all(result.get('passed', False) for result in consistency_check.values()):
            log.error("å¢é‡æ›´æ–°åæ•°æ®ä¸€è‡´æ€§æ ¡éªŒå¤±è´¥")
            # å¯ä»¥è§¦å‘å›æ»š
            return False

        log.info("å¢é‡æ›´æ–°æˆåŠŸä¸”æ•°æ®ä¸€è‡´æ€§æ ¡éªŒé€šè¿‡")
        return True

    except Exception as e:
        log.error(f"å¢é‡æ›´æ–°å¤±è´¥: {e}")
        # è§¦å‘å›æ»š
        await self.rollback_incremental_update(symbol)
        return False
```

## ğŸ“ˆ ä½¿ç”¨ç¤ºä¾‹

### å‘½ä»¤è¡Œä½¿ç”¨

#### æ•°æ®æ ¡éªŒ
```bash
# æ ¡éªŒæ‰€æœ‰æ•°æ®å±‚
python data_manager.py validate --symbol BTC_PRICE --data-type all

# åªæ ¡éªŒCleanæ•°æ®
python data_manager.py validate --symbol BTC_PRICE --data-type clean
```

#### å¢é‡æ›´æ–°å®‰å…¨æ£€æŸ¥
```bash
# æ£€æŸ¥å¢é‡æ›´æ–°å®‰å…¨æ€§
python data_manager.py safety_check --symbol BTC_PRICE --data-type clean
```

#### è´¨é‡ç›‘æ§æ¼”ç¤º
```bash
# è¿è¡Œè´¨é‡ç›‘æ§æ¼”ç¤º
python quality_monitor_demo.py
```

### ç¼–ç¨‹æ¥å£

#### åŸºç¡€æ ¡éªŒ
```python
from modules.validation.data_validator import data_validator, ValidationLevel

# æ ¡éªŒDataFrame
report = data_validator.validate_clean_data(df, 'predict', 'BTC_PRICE', ValidationLevel.STANDARD)

if report.is_pass:
    print(f"âœ… æ ¡éªŒé€šè¿‡ï¼Œè´¨é‡è¯„åˆ†: {report.score:.1f}")
else:
    print(f"âŒ æ ¡éªŒå¤±è´¥ï¼Œå‘ç° {len(report.issues)} ä¸ªé—®é¢˜")

# ç”ŸæˆæŠ¥å‘Š
html_report = data_validator.generate_validation_report(report, "html")
```

#### è´¨é‡ç›‘æ§
```python
from modules.validation.quality_monitor import quality_monitor

# æ‰§è¡Œè´¨é‡æ£€æŸ¥
report = await quality_monitor.run_quality_check(['raw', 'clean', 'feature'])

# æŸ¥çœ‹å‘Šè­¦
active_alerts = quality_monitor.get_active_alerts()
for alert in active_alerts:
    print(f"ğŸš¨ {alert.level}: {alert.message}")

# ç”Ÿæˆä»ªè¡¨æ¿
dashboard_html = quality_monitor.generate_quality_dashboard()
```

#### å¢é‡æ ¡éªŒ
```python
# å¢é‡æ›´æ–°æ ¡éªŒ
validation_report = data_validator.validate_incremental_update(
    existing_data, new_data, 'BTC_PRICE', 'clean'
)

if validation_report.is_pass:
    print("âœ… å¢é‡æ›´æ–°å®‰å…¨")
    # æ‰§è¡Œæ›´æ–°
else:
    print("âŒ å¢é‡æ›´æ–°å­˜åœ¨é£é™©")
    # æ‹’ç»æ›´æ–°æˆ–æ‰§è¡Œä¿®å¤
```

## ğŸ¯ æœ€ä½³å®è·µ

### æ ¡éªŒç­–ç•¥
1. **åˆ†å±‚æ ¡éªŒ**: Rawâ†’Cleanâ†’Featureé€æ­¥ä¸¥æ ¼
2. **å¢é‡æ£€æŸ¥**: æ–°æ•°æ®ä¼˜å…ˆè¿›è¡Œå®Œæ•´æ€§æ ¡éªŒ
3. **å®šæœŸé‡æ£€**: å®šæœŸå¯¹å†å²æ•°æ®è¿›è¡Œé‡æ–°æ ¡éªŒ
4. **å‘Šè­¦å“åº”**: å»ºç«‹å‘Šè­¦å“åº”å’Œå¤„ç†æµç¨‹

### æ€§èƒ½ä¼˜åŒ–
1. **é‡‡æ ·æ ¡éªŒ**: å¯¹å¤§æ•°æ®é›†ä½¿ç”¨é‡‡æ ·æ ¡éªŒ
2. **å¼‚æ­¥å¤„ç†**: æ ¡éªŒä»»åŠ¡å¼‚æ­¥æ‰§è¡Œä¸é˜»å¡ä¸»æµç¨‹
3. **ç¼“å­˜ç»“æœ**: ç¼“å­˜è¿‘æœŸæ ¡éªŒç»“æœé¿å…é‡å¤è®¡ç®—
4. **åˆ†æ‰¹å¤„ç†**: å¤§æ•°æ®åˆ†æ‰¹æ ¡éªŒé¿å…å†…å­˜æº¢å‡º

### ç›‘æ§å‘Šè­¦
1. **é˜ˆå€¼è®¾ç½®**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½®åˆç†çš„è´¨é‡é˜ˆå€¼
2. **å‘Šè­¦åˆ†çº§**: warning/error/critical ä¸‰çº§å‘Šè­¦ä½“ç³»
3. **å“åº”æœºåˆ¶**: å»ºç«‹è‡ªåŠ¨å“åº”å’Œäººå·¥å¹²é¢„æœºåˆ¶
4. **è¶‹åŠ¿åˆ†æ**: ç›‘æ§è´¨é‡å˜åŒ–è¶‹åŠ¿ï¼Œé¢„æµ‹æ½œåœ¨é—®é¢˜

### æ•°æ®ä¿®å¤
1. **è‡ªåŠ¨ä¿®å¤**: å¯¹å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜å®æ–½è‡ªåŠ¨ä¿®å¤
2. **äººå·¥å®¡æ ¸**: å¤æ‚é—®é¢˜é€šè¿‡äººå·¥å®¡æ ¸å¤„ç†
3. **ç‰ˆæœ¬æ§åˆ¶**: ä¿®å¤æ“ä½œè®°å½•ç‰ˆæœ¬ä¾¿äºå›æº¯
4. **é¢„é˜²æªæ–½**: åŸºäºæ ¡éªŒç»“æœæ”¹è¿›æ•°æ®é‡‡é›†æµç¨‹

è¿™ä¸ªæ•°æ®å®Œæ•´æ€§å’Œæ ¡éªŒæœºåˆ¶ä¸ºPredictLabæä¾›äº†ä¼ä¸šçº§çš„**æ•°æ®è´¨é‡ä¿éšœ**ï¼Œç¡®ä¿ä»æ•°æ®æºå¤´åˆ°æœ€ç»ˆåˆ†æçš„**æ•°æ®å¯ä¿¡åº¦**ï¼ ğŸ›¡ï¸âœ¨
