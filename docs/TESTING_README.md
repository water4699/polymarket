# PredictLab æµ‹è¯•æŒ‡å—

PredictLab å®ç°äº†å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œæµ‹è¯•ç­–ç•¥ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šå¯é ã€‚æœ¬æ–‡æ¡£ä»‹ç»æµ‹è¯•æ¡†æ¶ã€è¿è¡Œæ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

## ğŸ“‹ ç›®å½•

- [æµ‹è¯•æ¶æ„](#æµ‹è¯•æ¶æ„)
- [å¼‚å¸¸å¤„ç†](#å¼‚å¸¸å¤„ç†)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æµ‹è¯•ç±»å‹](#æµ‹è¯•ç±»å‹)
- [è¿è¡Œæµ‹è¯•](#è¿è¡Œæµ‹è¯•)
- [æµ‹è¯•è¦†ç›–](#æµ‹è¯•è¦†ç›–)
- [æŒç»­é›†æˆ](#æŒç»­é›†æˆ)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸ—ï¸ æµ‹è¯•æ¶æ„

### ç›®å½•ç»“æ„

```
tests/
â”œâ”€â”€ conftest.py              # pytest é…ç½®å’Œå…±äº«å¤¹å…·
â”œâ”€â”€ pytest.ini              # pytest é…ç½®æ–‡ä»¶
â”œâ”€â”€ test_utils.py           # æµ‹è¯•è¾…åŠ©å·¥å…·
â”œâ”€â”€ run_tests.py            # æµ‹è¯•è¿è¡Œè„šæœ¬
â”œâ”€â”€ unit/                   # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_data_source.py     # æ•°æ®æºæµ‹è¯•
â”‚   â”œâ”€â”€ test_data_processing.py # æ•°æ®å¤„ç†æµ‹è¯•
â”‚   â”œâ”€â”€ test_data_storage.py    # æ•°æ®å­˜å‚¨æµ‹è¯•
â”‚   â””â”€â”€ test_analysis.py        # åˆ†ææµ‹è¯•
â”œâ”€â”€ integration/            # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_full_pipeline.py   # å®Œæ•´ç®¡é“æµ‹è¯•
â””â”€â”€ fixtures/               # æµ‹è¯•æ•°æ®å’Œé…ç½®
```

### æ ¸å¿ƒç»„ä»¶

- **å¼‚å¸¸å¤„ç†ç³»ç»Ÿ**: ç»Ÿä¸€çš„é”™è¯¯æ•è·ã€æ—¥å¿—è®°å½•å’Œæ¢å¤æœºåˆ¶
- **æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨**: è‡ªåŠ¨ç”Ÿæˆå„ç§æµ‹è¯•æ•°æ®
- **æ¨¡æ‹Ÿå¯¹è±¡å·¥å‚**: åˆ›å»ºå¯é¢„æµ‹çš„æµ‹è¯•ä¾èµ–
- **æ–­è¨€å·¥å…·**: ä¸“é—¨çš„æµ‹è¯•æ–­è¨€å‡½æ•°

## âš ï¸ å¼‚å¸¸å¤„ç†

### å¼‚å¸¸å±‚æ¬¡ç»“æ„

```
PredictLabError (åŸºç¡€å¼‚å¸¸)
â”œâ”€â”€ DataSourceError (æ•°æ®æºå¼‚å¸¸)
â”‚   â”œâ”€â”€ DataSourceConnectionError
â”‚   â”œâ”€â”€ DataFetchError
â”‚   â””â”€â”€ APIKeyError
â”œâ”€â”€ DataProcessingError (æ•°æ®å¤„ç†å¼‚å¸¸)
â”‚   â”œâ”€â”€ DataValidationError
â”‚   â”œâ”€â”€ DataCleaningError
â”‚   â””â”€â”€ KlineGenerationError
â”œâ”€â”€ DataStorageError (æ•°æ®å­˜å‚¨å¼‚å¸¸)
â”‚   â”œâ”€â”€ DatabaseConnectionError
â”‚   â””â”€â”€ DatabaseOperationError
â”œâ”€â”€ AnalysisError (åˆ†æå¼‚å¸¸)
â”‚   â”œâ”€â”€ BacktestError
â”‚   â””â”€â”€ StrategyError
â”œâ”€â”€ VisualizationError (å¯è§†åŒ–å¼‚å¸¸)
â”œâ”€â”€ SchedulerError (è°ƒåº¦å¼‚å¸¸)
â”œâ”€â”€ ConfigurationError (é…ç½®å¼‚å¸¸)
â””â”€â”€ ValidationError (éªŒè¯å¼‚å¸¸)
```

### å¼‚å¸¸å¤„ç†è£…é¥°å™¨

```python
from utils.error_handler import handle_errors, safe_call

# åŸºæœ¬é”™è¯¯å¤„ç†
@handle_errors("operation_name", retry_count=3)
def risky_operation():
    # å¯èƒ½å¤±è´¥çš„æ“ä½œ
    pass

# å¼‚æ­¥é”™è¯¯å¤„ç†
@handle_async_errors("async_operation", severity=ErrorSeverity.HIGH)
async def async_risky_operation():
    pass

# å®‰å…¨è°ƒç”¨
result = safe_call(may_fail_function, default_return=None)
```

### ç†”æ–­å™¨æ¨¡å¼

```python
from utils.error_handler import CircuitBreaker

@CircuitBreaker(failure_threshold=5, recovery_timeout=60)
def api_call():
    # API è°ƒç”¨ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨ç†”æ–­
    pass
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# ä½¿ç”¨æµ‹è¯•è¿è¡Œå™¨ï¼ˆæ¨èï¼‰
python run_tests.py all

# æˆ–ç›´æ¥ä½¿ç”¨ pytest
pytest
```

### 3. è¿è¡Œå•å…ƒæµ‹è¯•

```bash
python run_tests.py unit
```

### 4. è¿è¡Œé›†æˆæµ‹è¯•

```bash
python run_tests.py integration
```

### 5. ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š

```bash
python run_tests.py coverage
```

## ğŸ“Š æµ‹è¯•ç±»å‹

### å•å…ƒæµ‹è¯• (Unit Tests)

æµ‹è¯•å•ä¸ªç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½ï¼š

```python
import pytest
from modules.data_processing.data_cleaner import DataCleaner

def test_data_cleaner_init():
    cleaner = DataCleaner()
    assert cleaner is not None

def test_clean_market_data(sample_market_data):
    cleaner = DataCleaner()
    cleaned = cleaner.clean_market_data(sample_market_data)
    assert not cleaned.empty
```

### é›†æˆæµ‹è¯• (Integration Tests)

æµ‹è¯•ç»„ä»¶é—´çš„äº¤äº’ï¼š

```python
@pytest.mark.integration
async def test_data_pipeline_integration(mock_data_source, mock_storage):
    # æµ‹è¯•å®Œæ•´çš„æ•°æ®ç®¡é“
    await mock_data_source.connect()
    data = await mock_data_source.fetch_data("BTC_PRICE")

    await mock_storage.connect()
    await mock_storage.insert_raw_market_data(data)

    # éªŒè¯æ•°æ®æµ
    stored_data = await mock_storage.get_raw_market_data("BTC_PRICE")
    assert not stored_data.empty
```

### æ€§èƒ½æµ‹è¯• (Performance Tests)

```python
@pytest.mark.slow
def test_large_dataset_processing():
    # ç”Ÿæˆå¤§é‡æ•°æ®
    large_data = TestDataGenerator.generate_market_data(
        MarketDataSpec(data_points=10000)
    )

    # æµ‹è¯•å¤„ç†æ€§èƒ½
    start_time = time.time()
    result = process_data(large_data)
    duration = time.time() - start_time

    assert duration < 30  # åº”è¯¥åœ¨30ç§’å†…å®Œæˆ
```

## ğŸƒ è¿è¡Œæµ‹è¯•

### åŸºæœ¬å‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python run_tests.py all

# è¿è¡Œå•å…ƒæµ‹è¯•
python run_tests.py unit

# è¿è¡Œé›†æˆæµ‹è¯•
python run_tests.py integration

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
python run_tests.py specific tests/unit/test_data_source.py

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python run_tests.py performance

# æ£€æŸ¥æµ‹è¯•ç»“æ„
python run_tests.py check
```

### pytest ç›´æ¥å‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest --cov=. --cov-report=html

# è¿è¡Œç‰¹å®šæ ‡è®°çš„æµ‹è¯•
pytest -m "integration and not slow"

# è¿è¡Œç‰¹å®šæ–‡ä»¶çš„æµ‹è¯•
pytest tests/unit/test_data_source.py::TestPredictSource::test_fetch_data

# å¹¶è¡Œè¿è¡Œ
pytest -n auto

# æ˜¾ç¤ºæœ€æ…¢çš„æµ‹è¯•
pytest --durations=10
```

### ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®æµ‹è¯•ç¯å¢ƒ
export PREDICTLAB_ENV=testing

# ç¦ç”¨æ—¥å¿—
export PYTEST_DISABLE_PLUGIN_AUTOLOAD=1

# è®¾ç½®å¹¶è¡Œè¿›ç¨‹æ•°
export PYTEST_XDIST_WORKER_COUNT=4
```

## ğŸ“ˆ æµ‹è¯•è¦†ç›–

### è¦†ç›–ç‡ç›®æ ‡

- **å•å…ƒæµ‹è¯•**: â‰¥ 80%
- **é›†æˆæµ‹è¯•**: â‰¥ 70%
- **æ€»è¦†ç›–ç‡**: â‰¥ 75%

### æŸ¥çœ‹è¦†ç›–ç‡

```bash
# ç”Ÿæˆ HTML æŠ¥å‘Š
python run_tests.py coverage

# æŸ¥çœ‹ç»ˆç«¯æŠ¥å‘Š
pytest --cov=. --cov-report=term-missing

# æŸ¥çœ‹å…·ä½“æ–‡ä»¶è¦†ç›–
pytest --cov=modules.data_source --cov-report=html
```

### è¦†ç›–ç‡é…ç½®

pytest.ini ä¸­çš„è¦†ç›–ç‡è®¾ç½®ï¼š

```ini
[tool:pytest]
addopts =
    --cov=.
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
```

## ğŸ”„ æŒç»­é›†æˆ

### GitHub Actions ç¤ºä¾‹

```yaml
name: Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    - name: Install dependencies
      run: pip install -r requirements.txt
    - name: Run tests
      run: python run_tests.py all
    - name: Upload coverage
      uses: codecov/codecov-action@v2
```

### æœ¬åœ° CI è„šæœ¬

```bash
#!/bin/bash
# ci.sh

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œæµ‹è¯•
python run_tests.py all

# æ£€æŸ¥è¦†ç›–ç‡
coverage report --fail-under=80

# è¿è¡Œé™æ€æ£€æŸ¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
# flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
# mypy .
```

## ğŸ§ª æµ‹è¯•æ•°æ®å’Œæ¨¡æ‹Ÿ

### æµ‹è¯•æ•°æ®ç”Ÿæˆ

```python
from tests.test_utils import TestDataGenerator, MarketDataSpec

# ç”Ÿæˆå¸‚åœºæ•°æ®
spec = MarketDataSpec(
    symbol="BTC_PRICE",
    base_price=40000,
    data_points=100,
    volatility=0.02
)
market_data = TestDataGenerator.generate_market_data(spec)

# ç”ŸæˆKçº¿æ•°æ®
kline_data = TestDataGenerator.generate_kline_data("BTC_PRICE", "1h", 50)

# ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡
indicators = TestDataGenerator.generate_technical_indicators(kline_data)

# ç”Ÿæˆäº¤æ˜“ä¿¡å·
signals = TestDataGenerator.generate_trading_signals(kline_data, 'ma_cross')
```

### æ¨¡æ‹Ÿå¯¹è±¡

```python
from tests.test_utils import MockFactory

# åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æº
mock_source = MockFactory.create_mock_data_source(success=True)

# åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨
mock_storage = MockFactory.create_mock_storage(success=True)

# åˆ›å»ºæ¨¡æ‹ŸAPIå“åº”
mock_response = MockFactory.create_mock_api_response(200, {"data": []})
```

### è‡ªå®šä¹‰æ–­è¨€

```python
from tests.test_utils import TestAssertions

# æ–­è¨€ DataFrame ç»“æ„
TestAssertions.assert_dataframe_structure(df, ['timestamp', 'price', 'volume'])

# æ–­è¨€ OHLCV å®Œæ•´æ€§
TestAssertions.assert_ohlcv_integrity(kline_data)

# æ–­è¨€äº¤æ˜“ä¿¡å·æœ‰æ•ˆæ€§
TestAssertions.assert_signals_valid(signals_df)

# æ–­è¨€å›æµ‹ç»“æœ
TestAssertions.assert_backtest_results(backtest_results)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æµ‹è¯•è¶…æ—¶

```bash
# å¢åŠ è¶…æ—¶æ—¶é—´
pytest --timeout=300

# æˆ–åœ¨æµ‹è¯•ä¸Šæ·»åŠ æ ‡è®°
@pytest.mark.slow
def test_slow_operation():
    pass
```

#### 2. å¼‚æ­¥æµ‹è¯•å¤±è´¥

```bash
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å¼‚æ­¥æ ‡è®°
@pytest.mark.asyncio
async def test_async_function():
    pass
```

#### 3. æ•°æ®åº“æµ‹è¯•å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®åº“é…ç½®
export PREDICTLAB_ENV=testing

# æˆ–è€…è·³è¿‡æ•°æ®åº“æµ‹è¯•
pytest -m "not database"
```

#### 4. è¦†ç›–ç‡æŠ¥å‘Šä¸ç”Ÿæˆ

```bash
# æ¸…é™¤ç¼“å­˜
pytest --cache-clear

# é‡æ–°ç”ŸæˆæŠ¥å‘Š
python run_tests.py coverage
```

#### 5. å¯¼å…¥é”™è¯¯

```bash
# æ£€æŸ¥ Python è·¯å¾„
export PYTHONPATH=$PWD:$PYTHONPATH

# æˆ–åœ¨æµ‹è¯•æ–‡ä»¶å¼€å¤´æ·»åŠ 
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
```

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è°ƒè¯•æ¨¡å¼
pytest -s -v --pdb

# åªè¿è¡Œå¤±è´¥çš„æµ‹è¯•
pytest --lf

# æ˜¾ç¤ºæ‰€æœ‰è¾“å‡º
pytest -s

# è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
pytest --tb=long
```

## ğŸ“ ç¼–å†™æµ‹è¯•çš„æœ€ä½³å®è·µ

### 1. æµ‹è¯•å‘½å

```python
# å¥½çš„å‘½å
def test_data_cleaner_handles_missing_values():
def test_strategy_generates_valid_signals():
def test_storage_inserts_data_successfully():

# ä¸å¥½çš„å‘½å
def test_func():
def test_stuff():
```

### 2. æµ‹è¯•ç»“æ„

```python
class TestMyComponent:
    def setup_method(self):
        # æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®
        pass

    def teardown_method(self):
        # æ¯ä¸ªæµ‹è¯•åçš„æ¸…ç†
        pass

    def test_normal_operation(self):
        # æ­£å¸¸æƒ…å†µæµ‹è¯•
        pass

    def test_edge_cases(self):
        # è¾¹ç•Œæƒ…å†µæµ‹è¯•
        pass

    def test_error_conditions(self):
        # é”™è¯¯æƒ…å†µæµ‹è¯•
        pass
```

### 3. ä½¿ç”¨å¤¹å…·

```python
@pytest.fixture
def sample_data(self):
    return generate_test_data()

def test_with_sample_data(sample_data):
    result = process_data(sample_data)
    assert result is not None
```

### 4. æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–

```python
def test_api_call_with_mock(mocker):
    mock_response = mocker.Mock()
    mock_response.status_code = 200
    mock_response.json.return_value = {"data": []}

    mocker.patch('requests.get', return_value=mock_response)

    result = api_call()
    assert result.success
```

### 5. å‚æ•°åŒ–æµ‹è¯•

```python
@pytest.mark.parametrize("input_value,expected", [
    (1, 2),
    (2, 4),
    (3, 6),
])
def test_double(input_value, expected):
    assert double(input_value) == expected
```

## ğŸ“Š æµ‹è¯•æŒ‡æ ‡

### è´¨é‡æŒ‡æ ‡

- **æµ‹è¯•é€šè¿‡ç‡**: â‰¥ 99%
- **æµ‹è¯•è¦†ç›–ç‡**: â‰¥ 80%
- **æµ‹è¯•æ‰§è¡Œæ—¶é—´**: < 5åˆ†é’Ÿ
- **å¤±è´¥æµ‹è¯•é‡è¯•ç‡**: < 1%

### ç›‘æ§æŒ‡æ ‡

```python
# åœ¨ CI/CD ä¸­ç›‘æ§
def test_quality_metrics():
    # æµ‹è¯•æ•°é‡
    # è¦†ç›–ç‡
    # æ‰§è¡Œæ—¶é—´
    # å¤±è´¥ç‡
    pass
```

## ğŸ”§ ç»´æŠ¤æŒ‡å—

### æ·»åŠ æ–°æµ‹è¯•

1. ç¡®å®šæµ‹è¯•ç±»å‹ï¼ˆå•å…ƒ/é›†æˆï¼‰
2. åˆ›å»ºç›¸åº”çš„æµ‹è¯•æ–‡ä»¶
3. ç¼–å†™æµ‹è¯•ç”¨ä¾‹
4. æ·»åŠ å¿…è¦çš„æµ‹è¯•æ•°æ®
5. è¿è¡Œæµ‹è¯•éªŒè¯
6. æ›´æ–°æ–‡æ¡£

### æ›´æ–°ç°æœ‰æµ‹è¯•

1. åˆ†æå˜æ›´å½±å“
2. ä¿®æ”¹ç›¸å…³æµ‹è¯•
3. è¿è¡Œå›å½’æµ‹è¯•
4. æ›´æ–°æµ‹è¯•æ•°æ®
5. éªŒè¯è¦†ç›–ç‡

### æµ‹è¯•é‡æ„

1. è¯†åˆ«é‡å¤ä»£ç 
2. æå–å…¬å…±å¤¹å…·
3. ç®€åŒ–æµ‹è¯•é€»è¾‘
4. æ”¹è¿›æ–­è¨€
5. æ›´æ–°æ–‡æ¡£

---

*æœ€åæ›´æ–°: 2024-01-16*
*æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡: â‰¥ 80%*
