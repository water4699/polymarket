#!/usr/bin/env python3
"""
PredictLab åŸå‹ç‰ˆæœ¬ä¸»ç¨‹åºå…¥å£
ç®€åŒ–ç‰ˆæ•°æ®åˆ†æå¹³å°ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£
"""
import asyncio
import sys
import argparse
from datetime import datetime, timedelta
from typing import Dict, Any
from config import config
from utils.logger import get_logger

# æ ¸å¿ƒæ¨¡å—å¯¼å…¥
from modules.data_source.predict_source import PredictDataSource
from modules.data_source.polymarket_source import PolymarketDataSource
from modules.data_source.onchain_source import OnChainDataSource
from modules.data_source.dune_source import DuneDataSource

from modules.data_storage.postgres_storage import PostgresStorage
from modules.data_storage.mongo_storage import MongoStorage

from modules.data_processing.data_cleaner import DataCleaner
from modules.data_processing.kline_generator import KlineGenerator

# ç®€åŒ–åˆ†æå·¥å…·
from modules.analysis.simple_analyzer import (
    SimpleStrategy, SimpleBacktester, SimpleChartGenerator, SimpleScheduler,
    simple_backtester, simple_chart_generator, simple_scheduler
)

# å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å™¨
from modules.scheduler.async_pipeline_runner import AsyncPipelineRunner

logger = get_logger(__name__)


class PredictLabPrototype:
    """PredictLab åŸå‹ç‰ˆæœ¬"""

    def __init__(self):
        # æ ¸å¿ƒç»„ä»¶
        self.data_sources = {}
        self.storage = {}
        self.data_cleaner = DataCleaner()
        self.kline_generator = KlineGenerator()

        # åˆ†æå·¥å…·
        self.strategy = SimpleStrategy()
        self.backtester = simple_backtester
        self.chart_generator = simple_chart_generator
        self.scheduler = simple_scheduler

        logger.info("PredictLab åŸå‹ç‰ˆæœ¬åˆå§‹åŒ–å®Œæˆ")

    async def init_core_components(self):
        """åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶"""
        logger.info("åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶...")

        # åˆå§‹åŒ–æ•°æ®æº
        await self._init_data_sources()
        # åˆå§‹åŒ–å­˜å‚¨
        await self._init_storage()

        logger.info("æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    async def _init_data_sources(self):
        """åˆå§‹åŒ–æ•°æ®æº"""
        # Predict æ•°æ®æº
        predict_ds = PredictDataSource()
        if await predict_ds.connect():
            self.data_sources['predict'] = predict_ds

        # Polymarket æ•°æ®æº
        polymarket_ds = PolymarketDataSource()
        if await polymarket_ds.connect():
            self.data_sources['polymarket'] = polymarket_ds

        # é“¾ä¸Šæ•°æ®æº
        onchain_ds = OnChainDataSource()
        if await onchain_ds.connect():
            self.data_sources['onchain'] = onchain_ds

        # Dune æ•°æ®æº
        dune_ds = DuneDataSource()
        if await dune_ds.connect():
            self.data_sources['dune'] = dune_ds

        logger.info(f"æ•°æ®æºåˆå§‹åŒ–å®Œæˆ: {len(self.data_sources)} ä¸ªå¯ç”¨")

    async def _init_storage(self):
        """åˆå§‹åŒ–å­˜å‚¨"""
        # PostgreSQL å­˜å‚¨
        postgres_storage = PostgresStorage()
        if await postgres_storage.connect():
            self.storage['postgres'] = postgres_storage

        # MongoDB å­˜å‚¨
        mongo_storage = MongoStorage()
        if await mongo_storage.connect():
            self.storage['mongo'] = mongo_storage

        logger.info(f"å­˜å‚¨åˆå§‹åŒ–å®Œæˆ: {len(self.storage)} ä¸ªå¯ç”¨")

    async def run_quick_demo(self):
        """è¿è¡Œå¿«é€Ÿæ¼”ç¤º"""
        logger.info("å¼€å§‹è¿è¡Œå¿«é€Ÿæ¼”ç¤º...")

        try:
            # 1. å¿«é€Ÿæ•°æ®é‡‡é›†
            data = await self._quick_data_fetch()

            # 2. æ•°æ®å¤„ç†
            processed_data = self._quick_data_process(data)

            # 3. ç®€å•åˆ†æ
            analysis_result = self._quick_analysis(processed_data)

            # 4. ç»“æœå±•ç¤º
            self._display_results(analysis_result)

            logger.info("å¿«é€Ÿæ¼”ç¤ºå®Œæˆ")

        except Exception as e:
            logger.error(f"å¿«é€Ÿæ¼”ç¤ºå¤±è´¥: {e}")

    async def _quick_data_fetch(self) -> Dict[str, Any]:
        """å¿«é€Ÿæ•°æ®é‡‡é›†"""
        logger.info("æ‰§è¡Œå¿«é€Ÿæ•°æ®é‡‡é›†...")

        # ä¼˜å…ˆä½¿ç”¨ Predict æ•°æ®æº
        if 'predict' in self.data_sources:
            try:
                ds = self.data_sources['predict']
                end_time = datetime.now()
                start_time = end_time - timedelta(days=7)

                data = await ds.fetch_data(
                    market_id="BTC_PRICE",
                    start_time=start_time,
                    end_time=end_time
                )

                if not data.empty:
                    logger.info(f"é‡‡é›†åˆ°çœŸå®æ•°æ®: {len(data)} æ¡è®°å½•")
                    return {'source': 'predict', 'data': data}
            except Exception as e:
                logger.warning(f"Predict æ•°æ®é‡‡é›†å¤±è´¥: {e}")

        # å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        return {'source': 'mock', 'data': self._generate_mock_data()}

    def _generate_mock_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        import numpy as np

        timestamps = pd.date_range(
            start=datetime.now() - timedelta(days=30),
            end=datetime.now(),
            freq='1H'
        )

        np.random.seed(42)
        prices = []
        base_price = 50000.0

        for _ in timestamps:
            change = np.random.normal(0, 0.02)
            base_price *= (1 + change)
            prices.append(base_price)

        return pd.DataFrame({
            'timestamp': timestamps,
            'price': prices,
            'volume': np.random.uniform(100000, 1000000, len(timestamps))
        })

    def _quick_data_process(self, fetch_result: Dict[str, Any]):
        """å¿«é€Ÿæ•°æ®å¤„ç†"""
        logger.info("æ‰§è¡Œæ•°æ®å¤„ç†...")

        data = fetch_result['data']

        # æ•°æ®æ¸…æ´—
        cleaned_data = self.data_cleaner.clean_market_data(data)
        logger.info(f"æ•°æ®æ¸…æ´—: {len(data)} -> {len(cleaned_data)} è¡Œ")

        # ç”ŸæˆKçº¿
        kline_data = self.kline_generator.generate_klines(
            cleaned_data,
            interval='1d',
            price_col='price',
            volume_col='volume',
            timestamp_col='timestamp'
        )
        logger.info(f"Kçº¿ç”Ÿæˆ: {len(kline_data)} æ¡è®°å½•")

        return {
            'original': data,
            'cleaned': cleaned_data,
            'klines': kline_data,
            'source': fetch_result['source']
        }

    def _quick_analysis(self, processed_data: Dict[str, Any]):
        """å¿«é€Ÿåˆ†æ"""
        logger.info("æ‰§è¡Œç®€å•åˆ†æ...")

        kline_data = processed_data['klines']

        # ç®€å•å›æµ‹
        backtest_result = self.backtester.run_backtest(kline_data, self.strategy)

        # ç”Ÿæˆå›¾è¡¨
        price_chart = self.chart_generator.plot_price_chart(kline_data, "ä»·æ ¼èµ°åŠ¿")
        backtest_report = self.chart_generator.plot_backtest_result(backtest_result)

        return {
            'processed_data': processed_data,
            'backtest': backtest_result,
            'charts': {
                'price_chart': price_chart,
                'backtest_report': backtest_report
            }
        }

    def _display_results(self, analysis_result: Dict[str, Any]):
        """æ˜¾ç¤ºç»“æœ"""
        print("\n" + "="*60)
        print("PredictLab åŸå‹æ¼”ç¤ºç»“æœ")
        print("="*60)

        # æ•°æ®ä¿¡æ¯
        processed = analysis_result['processed_data']
        print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        print(f"   æ•°æ®æº: {processed['source']}")
        print(f"   åŸå§‹æ•°æ®: {len(processed['original'])} è¡Œ")
        print(f"   æ¸…æ´—å: {len(processed['cleaned'])} è¡Œ")
        print(f"   Kçº¿æ•°æ®: {len(processed['klines'])} æ¡")

        # å›æµ‹ç»“æœ
        backtest = analysis_result['backtest']
        print(f"\nğŸ“ˆ å›æµ‹ç»“æœ:")
        print(f"   ç­–ç•¥: {backtest.get('strategy_name', 'N/A')}")
        print(".2f")
        print(".2f")
        print(".2%")
        print(f"   äº¤æ˜“æ¬¡æ•°: {backtest.get('total_trades', 0)}")

        # å›¾è¡¨å±•ç¤º
        print(f"\nğŸ“‹ åˆ†æå›¾è¡¨:")
        print(analysis_result['charts']['price_chart'])
        print("\n" + "-"*40)
        print(analysis_result['charts']['backtest_report'])

        print("\n" + "="*60)
        print("æ¼”ç¤ºå®Œæˆï¼å¯ä»¥å¼€å§‹è‡ªå®šä¹‰æ‰©å±•")
        print("="*60)

    async def run_custom_analysis(self, data_source: str = "mock", days: int = 30):
        """è¿è¡Œè‡ªå®šä¹‰åˆ†æ"""
        logger.info(f"è¿è¡Œè‡ªå®šä¹‰åˆ†æ: {data_source}, {days}å¤©æ•°æ®")

        # ç”Ÿæˆæˆ–è·å–æ•°æ®
        if data_source == "mock":
            data = self._generate_mock_data()
        else:
            # è¿™é‡Œå¯ä»¥æ‰©å±•å…¶ä»–æ•°æ®æº
            data = self._generate_mock_data()

        # å¤„ç†å’Œåˆ†æ
        processed = self._quick_data_process({'source': data_source, 'data': data})
        analysis = self._quick_analysis(processed)
        self._display_results(analysis)

    async def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        health = {
            'data_sources': len(self.data_sources),
            'storage': len(self.storage),
            'status': 'ready' if (self.data_sources or self.storage) else 'limited'
        }

        print("=== å¥åº·æ£€æŸ¥ ===")
        print(f"æ•°æ®æº: {health['data_sources']} ä¸ªå¯ç”¨")
        print(f"å­˜å‚¨: {health['storage']} ä¸ªå¯ç”¨")
        print(f"çŠ¶æ€: {health['status']}")

        return health

    def show_available_components(self):
        """æ˜¾ç¤ºå¯ç”¨ç»„ä»¶"""
        print("\n=== å¯ç”¨ç»„ä»¶ ===")

        print("æ•°æ®æº:")
        for name in self.data_sources.keys():
            print(f"  âœ“ {name}")

        print("å­˜å‚¨:")
        for name in self.storage.keys():
            print(f"  âœ“ {name}")

        print("åˆ†æå·¥å…·:")
        print("  âœ“ ç®€å•ç­–ç•¥")
        print("  âœ“ ç®€åŒ–å›æµ‹å™¨")
        print("  âœ“ æ–‡æœ¬å›¾è¡¨ç”Ÿæˆå™¨")
        print("  âœ“ ä»»åŠ¡è°ƒåº¦å™¨")
        print("  âœ“ å¼‚æ­¥ç®¡é“è°ƒåº¦å™¨")

    async def run_async_pipeline(self, max_concurrent: int = 2):
        """è¿è¡Œå¼‚æ­¥æ•°æ®ç®¡é“"""
        logger.info(f"å¯åŠ¨å¼‚æ­¥æ•°æ®ç®¡é“ (å¹¶å‘æ•°: {max_concurrent})")

        try:
            runner = AsyncPipelineRunner()
            result = await runner.run_pipeline(max_concurrent=min(max_concurrent, 5))

            if result['status'] == 'completed':
                print("ğŸ‰ å¼‚æ­¥æ•°æ®ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
                print(f"æ€»ä»»åŠ¡æ•°: {result['stats']['total_tasks']}")
                print(".1%")
                print(".1f")
            else:
                print(f"ğŸ’¥ å¼‚æ­¥æ•°æ®ç®¡é“æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        except Exception as e:
            logger.error(f"å¼‚æ­¥ç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}")
            print(f"ğŸ’¥ å¼‚æ­¥ç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}")

    async def run_partial_pipeline(self, target_stage: str, symbols: list):
        """è¿è¡Œéƒ¨åˆ†å¼‚æ­¥ç®¡é“"""
        logger.info(f"å¯åŠ¨éƒ¨åˆ†å¼‚æ­¥ç®¡é“: {target_stage}, èµ„äº§: {symbols}")

        try:
            runner = AsyncPipelineRunner()
            result = await runner.run_partial_pipeline(target_stage, symbols)

            if result['status'] == 'completed':
                print(f"ğŸ‰ éƒ¨åˆ†ç®¡é“ ({target_stage}) æ‰§è¡ŒæˆåŠŸï¼")
                stats = result['stats']
                print(f"æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
                print(".1%")
            else:
                print(f"ğŸ’¥ éƒ¨åˆ†ç®¡é“æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        except Exception as e:
            logger.error(f"éƒ¨åˆ†ç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}")
            print(f"ğŸ’¥ éƒ¨åˆ†ç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PredictLab åŸå‹ç‰ˆæœ¬ - å¿«é€Ÿè¿­ä»£æ•°æ®åˆ†æå¹³å°')
    parser.add_argument('--demo', action='store_true', help='è¿è¡Œå¿«é€Ÿæ¼”ç¤º')
    parser.add_argument('--pipeline', action='store_true', help='è¿è¡Œå¼‚æ­¥æ•°æ®ç®¡é“')
    parser.add_argument('--pipeline-stage', choices=['collect', 'clean', 'kline', 'backtest', 'visualize'],
                       help='è¿è¡Œåˆ°æŒ‡å®šç®¡é“é˜¶æ®µ')
    parser.add_argument('--analyze', choices=['mock', 'predict'], default='mock', help='è¿è¡Œè‡ªå®šä¹‰åˆ†æ')
    parser.add_argument('--days', type=int, default=30, help='åˆ†ææ•°æ®å¤©æ•°')
    parser.add_argument('--symbols', nargs='+', help='æŒ‡å®šå¤„ç†çš„èµ„äº§ç¬¦å·')
    parser.add_argument('--concurrent', type=int, default=2, help='ç®¡é“æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--health', action='store_true', help='å¥åº·æ£€æŸ¥')
    parser.add_argument('--components', action='store_true', help='æ˜¾ç¤ºå¯ç”¨ç»„ä»¶')

    args = parser.parse_args()

    app = PredictLabPrototype()

    try:
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        await app.init_core_components()

        if args.health:
            await app.health_check()

        elif args.components:
            app.show_available_components()

        elif args.pipeline:
            # è¿è¡Œå¼‚æ­¥æ•°æ®ç®¡é“
            await app.run_async_pipeline(max_concurrent=args.concurrent)

        elif args.pipeline_stage:
            # è¿è¡Œéƒ¨åˆ†ç®¡é“
            symbols = args.symbols or ['BTC_PRICE']
            await app.run_partial_pipeline(args.pipeline_stage, symbols)

        elif args.demo:
            await app.run_quick_demo()

        elif args.analyze:
            await app.run_custom_analysis(args.analyze, args.days)

        else:
            parser.print_help()
            print("\n" + "="*60)
            print("PredictLab åŸå‹ä½¿ç”¨ç¤ºä¾‹:")
            print("  python main.py --demo                      # å¿«é€Ÿæ¼”ç¤º")
            print("  python main.py --pipeline                  # å¼‚æ­¥æ•°æ®ç®¡é“")
            print("  python main.py --pipeline-stage collect    # è¿è¡Œåˆ°é‡‡é›†é˜¶æ®µ")
            print("  python main.py --symbols BTC_PRICE ETH_PRICE # æŒ‡å®šèµ„äº§")
            print("  python main.py --concurrent 3              # è®¾ç½®å¹¶å‘æ•°")
            print("  python main.py --analyze mock              # æ¨¡æ‹Ÿæ•°æ®åˆ†æ")
            print("  python main.py --health                   # å¥åº·æ£€æŸ¥")
            print("  python main.py --components               # æŸ¥çœ‹ç»„ä»¶")
            print("="*60)

    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        return 1

    return 0


if __name__ == "__main__":
    import pandas as pd
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
