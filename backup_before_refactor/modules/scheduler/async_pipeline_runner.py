#!/usr/bin/env python3
"""
å¼‚æ­¥æ•°æ®ç®¡é“è¿è¡Œå™¨
ä½¿ç”¨ PredictLab ä»»åŠ¡è°ƒåº¦å™¨æ‰§è¡Œå®Œæ•´çš„å¼‚æ­¥æ•°æ®å¤„ç†æµç¨‹
åŒ…å«é”™è¯¯å¤„ç†ã€å¹¶å‘æ§åˆ¶å’ŒçŠ¶æ€ç›‘æ§
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from modules.scheduler.task_scheduler import DataPipelineScheduler
from utils.logger import get_logger

logger = get_logger(__name__)


class AsyncPipelineRunner:
    """å¼‚æ­¥ç®¡é“è¿è¡Œå™¨"""

    def __init__(self):
        self.scheduler = DataPipelineScheduler()
        self.pipeline_config = {
            'symbols': ['BTC_PRICE', 'ETH_PRICE'],
            'source_types': ['predict'],
            'intervals': ['1h', '1d'],
            'days_back': 7,  # å¤„ç†æœ€è¿‘7å¤©çš„æ•°æ®
        }

    async def run_pipeline(self, max_concurrent: int = 2) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®ç®¡é“

        Args:
            max_concurrent: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°

        Returns:
            æ‰§è¡Œç»“æœç»Ÿè®¡
        """
        logger.info("å¼€å§‹è¿è¡Œå¼‚æ­¥æ•°æ®ç®¡é“")
        start_time = datetime.now()

        try:
            # åˆ›å»ºç®¡é“
            self.scheduler.create_data_pipeline(self.pipeline_config)

            # æ‰§è¡Œç®¡é“
            results = await self.scheduler.execute_pipeline(max_concurrent)

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            execution_time = (datetime.now() - start_time).total_seconds()
            stats = self._calculate_stats(results, execution_time)

            # æ‰“å°ç»“æœæŠ¥å‘Š
            self._print_execution_report(results, stats)

            return {
                'status': 'completed',
                'stats': stats,
                'results': results,
                'execution_time': execution_time
            }

        except Exception as e:
            logger.error(f"ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'execution_time': (datetime.now() - start_time).total_seconds()
            }

    async def run_partial_pipeline(self, target_stage: str, symbols: list = None) -> Dict[str, Any]:
        """
        è¿è¡Œéƒ¨åˆ†ç®¡é“ (ç”¨äºè°ƒè¯•æˆ–ç‰¹å®šé˜¶æ®µæ‰§è¡Œ)

        Args:
            target_stage: ç›®æ ‡é˜¶æ®µ (collect, clean, kline, backtest, visualize)
            symbols: æŒ‡å®šå¤„ç†çš„èµ„äº§

        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info(f"å¼€å§‹è¿è¡Œéƒ¨åˆ†ç®¡é“: {target_stage}")

        config = self.pipeline_config.copy()
        if symbols:
            config['symbols'] = symbols

        # æ ¹æ®ç›®æ ‡é˜¶æ®µè°ƒæ•´é…ç½®
        if target_stage == 'collect':
            config['intervals'] = []  # ä¸ç”ŸæˆKçº¿
        elif target_stage == 'clean':
            config['intervals'] = []
        elif target_stage == 'kline':
            pass  # æ­£å¸¸æ‰§è¡Œ
        elif target_stage == 'backtest':
            pass
        elif target_stage == 'visualize':
            pass

        try:
            self.scheduler.create_data_pipeline(config)
            results = await self.scheduler.execute_pipeline(max_concurrent=3)

            execution_time = sum(r.duration for r in results.values() if r.end_time)
            stats = self._calculate_stats(results, execution_time)

            return {
                'status': 'completed',
                'target_stage': target_stage,
                'stats': stats,
                'results': results
            }

        except Exception as e:
            logger.error(f"éƒ¨åˆ†ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'status': 'failed',
                'target_stage': target_stage,
                'error': str(e)
            }

    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–ç®¡é“çŠ¶æ€"""
        return self.scheduler.get_pipeline_status()

    def _calculate_stats(self, results: Dict[str, Any], execution_time: float) -> Dict[str, Any]:
        """è®¡ç®—æ‰§è¡Œç»Ÿè®¡"""
        total_tasks = len(results)
        successful_tasks = sum(1 for r in results.values() if r.status.name == 'SUCCESS')
        failed_tasks = sum(1 for r in results.values() if r.status.name == 'FAILED')
        skipped_tasks = sum(1 for r in results.values() if r.status.name == 'SKIPPED')

        success_rate = successful_tasks / total_tasks if total_tasks > 0 else 0

        # æŒ‰é˜¶æ®µç»Ÿè®¡
        stage_stats = {}
        for task_id, result in results.items():
            stage = task_id.split('_')[0]  # collect, clean, kline, backtest, visualize
            if stage not in stage_stats:
                stage_stats[stage] = {'total': 0, 'success': 0, 'failed': 0}

            stage_stats[stage]['total'] += 1
            if result.status.name == 'SUCCESS':
                stage_stats[stage]['success'] += 1
            elif result.status.name == 'FAILED':
                stage_stats[stage]['failed'] += 1

        return {
            'total_tasks': total_tasks,
            'successful_tasks': successful_tasks,
            'failed_tasks': failed_tasks,
            'skipped_tasks': skipped_tasks,
            'success_rate': success_rate,
            'execution_time': execution_time,
            'tasks_per_second': total_tasks / execution_time if execution_time > 0 else 0,
            'stage_stats': stage_stats
        }

    def _print_execution_report(self, results: Dict[str, Any], stats: Dict[str, Any]):
        """æ‰“å°æ‰§è¡ŒæŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š PredictLab æ•°æ®ç®¡é“æ‰§è¡ŒæŠ¥å‘Š")
        print("="*80)

        print(f"\nâ±ï¸  æ‰§è¡Œæ—¶é—´: {stats['execution_time']:.2f} ç§’")
        print(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"âœ… æˆåŠŸä»»åŠ¡: {stats['successful_tasks']}")
        print(f"âŒ å¤±è´¥ä»»åŠ¡: {stats['failed_tasks']}")
        print(f"â­ï¸  è·³è¿‡ä»»åŠ¡: {stats['skipped_tasks']}")
        print(".1%")
        print(".1f")

        print(f"\nğŸ“ˆ é˜¶æ®µç»Ÿè®¡:")
        for stage, stage_stat in stats['stage_stats'].items():
            success_rate = stage_stat['success'] / stage_stat['total'] if stage_stat['total'] > 0 else 0
            print("5")

        # å¤±è´¥ä»»åŠ¡è¯¦æƒ…
        failed_results = {tid: r for tid, r in results.items() if r.status.name == 'FAILED'}
        if failed_results:
            print(f"\nâŒ å¤±è´¥ä»»åŠ¡è¯¦æƒ… ({len(failed_results)} ä¸ª):")
            for task_id, result in failed_results.items():
                print(f"   â€¢ {task_id}: {result.error} ({result.duration:.2f}s)")

        # æ€§èƒ½æœ€æ…¢çš„ä»»åŠ¡
        if results:
            slowest_tasks = sorted(
                [(tid, r.duration) for tid, r in results.items() if r.end_time],
                key=lambda x: x[1],
                reverse=True
            )[:5]

            print(f"\nğŸŒ æ‰§è¡Œæœ€æ…¢çš„ä»»åŠ¡:")
            for task_id, duration in slowest_tasks:
                print("5.2f")

        print("\n" + "="*80)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='PredictLab å¼‚æ­¥æ•°æ®ç®¡é“è¿è¡Œå™¨')
    parser.add_argument('--full', action='store_true', help='è¿è¡Œå®Œæ•´ç®¡é“')
    parser.add_argument('--stage', choices=['collect', 'clean', 'kline', 'backtest', 'visualize'],
                       help='è¿è¡Œåˆ°æŒ‡å®šé˜¶æ®µ')
    parser.add_argument('--symbols', nargs='+', help='æŒ‡å®šå¤„ç†çš„èµ„äº§ç¬¦å·')
    parser.add_argument('--concurrent', type=int, default=2, help='æœ€å¤§å¹¶å‘ä»»åŠ¡æ•° (1-5)')
    parser.add_argument('--status', action='store_true', help='æŸ¥çœ‹ç®¡é“çŠ¶æ€')

    args = parser.parse_args()

    runner = AsyncPipelineRunner()

    try:
        if args.status:
            # æŸ¥çœ‹çŠ¶æ€
            status = runner.get_pipeline_status()
            print("=== ç®¡é“çŠ¶æ€ ===")
            print(f"æ€»ä»»åŠ¡æ•°: {status['total_tasks']}")
            print(f"å·²å®Œæˆ: {status['completed_tasks']}")
            print(".1%")
            print(f"çŠ¶æ€åˆ†å¸ƒ: {status['status_breakdown']}")

        elif args.full:
            # è¿è¡Œå®Œæ•´ç®¡é“
            result = await runner.run_pipeline(max_concurrent=min(args.concurrent, 5))

            if result['status'] == 'completed':
                print("ğŸ‰ å®Œæ•´ç®¡é“æ‰§è¡ŒæˆåŠŸï¼"            else:
                print(f"ğŸ’¥ ç®¡é“æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        elif args.stage:
            # è¿è¡Œéƒ¨åˆ†ç®¡é“
            symbols = args.symbols or ['BTC_PRICE']
            result = await runner.run_partial_pipeline(args.stage, symbols)

            if result['status'] == 'completed':
                print(f"ğŸ‰ éƒ¨åˆ†ç®¡é“ ({args.stage}) æ‰§è¡ŒæˆåŠŸï¼"            else:
                print(f"ğŸ’¥ éƒ¨åˆ†ç®¡é“æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        else:
            parser.print_help()
            print("\n" + "="*60)
            print("PredictLab å¼‚æ­¥ç®¡é“ä½¿ç”¨ç¤ºä¾‹:")
            print("  python async_pipeline_runner.py --full              # å®Œæ•´ç®¡é“")
            print("  python async_pipeline_runner.py --stage collect     # åªé‡‡é›†æ•°æ®")
            print("  python async_pipeline_runner.py --stage kline       # ç”ŸæˆKçº¿")
            print("  python async_pipeline_runner.py --symbols BTC_PRICE # æŒ‡å®šèµ„äº§")
            print("  python async_pipeline_runner.py --concurrent 3      # 3å¹¶å‘")
            print("  python async_pipeline_runner.py --status           # æŸ¥çœ‹çŠ¶æ€")
            print("="*60)

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception as e:
        logger.error(f"æ‰§è¡Œå‡ºé”™: {e}")
        print(f"ğŸ’¥ æ‰§è¡Œå¤±è´¥: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
