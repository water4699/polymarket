#!/usr/bin/env python3
"""
Polymarketæ•°æ®å¯¼å…¥è„šæœ¬
å°†JSONæ•°æ®å¯¼å…¥åˆ°PostgreSQLæ•°æ®åº“ä¸­
"""

import json
import psycopg2
from psycopg2.extras import execute_values
from datetime import datetime
import os
from pathlib import Path

class PolymarketDataImporter:
    def __init__(self, db_config=None):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        if db_config:
            self.db_config = db_config
        else:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹é…ç½®
            self.db_config = self.detect_db_config()

    def detect_db_config(self):
        """è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“é…ç½®"""
        import os

        # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 5432)),
            'database': os.getenv('DB_NAME', 'polymarket'),
            'user': os.getenv('DB_USER'),
            'password': os.getenv('DB_PASSWORD')
        }

        # å¦‚æœç¯å¢ƒå˜é‡æ²¡æœ‰è®¾ç½®ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
        if not config['user']:
            current_user = os.getenv('USER') or os.getenv('USERNAME')

            # ä¼˜å…ˆä½¿ç”¨postgresç”¨æˆ·ï¼ˆPostgreSQLæ ‡å‡†è¶…çº§ç”¨æˆ·ï¼‰
            # å…¶æ¬¡å°è¯•ç³»ç»Ÿç”¨æˆ·
            possible_users = ['postgres', current_user]

            for user in possible_users:
                test_config = config.copy()
                test_config['user'] = user
                test_config['password'] = ''  # PostgreSQLé€šå¸¸é»˜è®¤ä¸éœ€è¦å¯†ç 

                if self.test_connection(test_config):
                    config['user'] = user
                    config['password'] = ''
                    print(f"âœ… è‡ªåŠ¨æ£€æµ‹åˆ°æ•°æ®åº“ç”¨æˆ·: {user}")
                    break
            else:
                # å¦‚æœè‡ªåŠ¨æ£€æµ‹éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨postgresä½œä¸ºé»˜è®¤å€¼
                # è¿™æ˜¯æœ€å¸¸è§çš„PostgreSQLé…ç½®
                config['user'] = 'postgres'
                config['password'] = ''
                print("â„¹ï¸  ä½¿ç”¨é»˜è®¤æ•°æ®åº“ç”¨æˆ·: postgres")

        return config

    def test_connection(self, config):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        try:
            # ä½¿ç”¨é»˜è®¤æ•°æ®åº“æµ‹è¯•è¿æ¥
            test_config = config.copy()
            test_config['database'] = 'postgres'

            conn = psycopg2.connect(**test_config)
            conn.close()
            return True
        except:
            return False
        self.conn = None

    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            self.conn.autocommit = False
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            print(f"   ç”¨æˆ·: {self.db_config['user']}")
            print(f"   æ•°æ®åº“: {self.db_config['database']}")
        except psycopg2.OperationalError as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            print("\\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            if "role" in str(e).lower() and "does not exist" in str(e).lower():
                print("   1. æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦æ­£ç¡® (é»˜è®¤åº”ä¸º 'postgres' æˆ–ä½ çš„ç³»ç»Ÿç”¨æˆ·å)")
                print("   2. è¿è¡Œ: python3 check_postgres_connection.py")
            elif "authentication failed" in str(e).lower():
                print("   1. æ£€æŸ¥å¯†ç æ˜¯å¦æ­£ç¡®")
                print("   2. å¯èƒ½éœ€è¦è®¾ç½®å¯†ç : ALTER USER your_username PASSWORD 'your_password';")
            elif "connection refused" in str(e).lower():
                print("   1. ç¡®ä¿PostgreSQLæœåŠ¡æ­£åœ¨è¿è¡Œ")
                print("   2. macOS: brew services start postgresql")
                print("   3. Linux: sudo systemctl start postgresql")
            elif "database" in str(e).lower() and "does not exist" in str(e).lower():
                print("   1. åˆ›å»ºæ•°æ®åº“: createdb polymarket")
                print("   2. æˆ–è€…è¿æ¥åˆ°é»˜è®¤æ•°æ®åº“ 'postgres' è¿›è¡Œæµ‹è¯•")
            else:
                print("   1. è¿è¡Œè¯Šæ–­è„šæœ¬: python3 check_postgres_connection.py")

            print(f"\\nğŸ”§ å½“å‰é…ç½®: {self.db_config}")
            raise
        except Exception as e:
            print(f"âŒ æœªçŸ¥æ•°æ®åº“é”™è¯¯: {e}")
            raise

    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def create_tables(self):
        """åˆ›å»ºæ•°æ®è¡¨"""
        schema_file = Path(__file__).parent / 'polymarket_db_schema.sql'
        if not schema_file.exists():
            print(f"âŒ æ‰¾ä¸åˆ°è¡¨ç»“æ„æ–‡ä»¶: {schema_file}")
            return False

        try:
            with open(schema_file, 'r', encoding='utf-8') as f:
                schema_sql = f.read()

            with self.conn.cursor() as cursor:
                cursor.execute(schema_sql)
                self.conn.commit()
                print("âœ… æ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
                return True
        except Exception as e:
            self.conn.rollback()
            print(f"âŒ è¡¨åˆ›å»ºå¤±è´¥: {e}")
            return False

    def load_json_file(self, file_path):
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"ğŸ“„ æˆåŠŸåŠ è½½æ–‡ä»¶: {file_path}")
                return data
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def parse_timestamp(self, timestamp_str):
        """è§£ææ—¶é—´æˆ³"""
        if not timestamp_str:
            return None

        # å¤„ç†ä¸åŒçš„æ—¶é—´æ ¼å¼
        formats = [
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%d %H:%M:%S%z',
            '%Y-%m-%d'
        ]

        for fmt in formats:
            try:
                if fmt.endswith('%z'):
                    # å¤„ç†æ—¶åŒºä¿¡æ¯
                    dt = datetime.strptime(timestamp_str, fmt)
                else:
                    dt = datetime.strptime(timestamp_str.replace('Z', ''), fmt)
                return dt
            except ValueError:
                continue
        return None

    def insert_market(self, market_data, category):
        """æ’å…¥å¸‚åœºæ•°æ®"""
        try:
            with self.conn.cursor() as cursor:
                # å‡†å¤‡å¸‚åœºæ•°æ®
                market_sql = """
                INSERT INTO markets (
                    id, question, condition_id, slug, description, resolution_source,
                    created_at, updated_at, start_date, end_date, closed_time,
                    active, closed, archived, restricted, featured, new,
                    volume, volume_24hr, volume_1wk, volume_1mo, volume_1yr, liquidity,
                    enable_order_book, accepting_orders, neg_risk, neg_risk_market_id,
                    uma_bond, uma_reward, uma_end_date, uma_resolution_status,
                    image, icon, submitted_by, category, data_source, sport_type
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
                ON CONFLICT (id) DO UPDATE SET
                    question = EXCLUDED.question,
                    updated_at = EXCLUDED.updated_at,
                    volume = EXCLUDED.volume,
                    liquidity = EXCLUDED.liquidity,
                    updated_at_db = NOW()
                """

                market_values = (
                    market_data.get('id'),
                    market_data.get('question'),
                    market_data.get('condition_id') or market_data.get('conditionId'),
                    market_data.get('slug'),
                    market_data.get('description'),
                    market_data.get('resolutionSource'),
                    self.parse_timestamp(market_data.get('createdAt')),
                    self.parse_timestamp(market_data.get('updatedAt')),
                    self.parse_timestamp(market_data.get('startDate') or market_data.get('start_date')),
                    self.parse_timestamp(market_data.get('endDate') or market_data.get('end_date')),
                    self.parse_timestamp(market_data.get('closedTime') or market_data.get('closed_time')),
                    market_data.get('active', True),
                    market_data.get('closed', False),
                    market_data.get('archived', False),
                    market_data.get('restricted', False),
                    market_data.get('featured', False),
                    market_data.get('new', True),
                    market_data.get('volumeNum') or market_data.get('volume'),
                    market_data.get('volume24hr') or market_data.get('volume_24hr'),
                    market_data.get('volume1wk') or market_data.get('volume_1wk'),
                    market_data.get('volume1mo') or market_data.get('volume_1mo'),
                    market_data.get('volume1yr') or market_data.get('volume_1yr'),
                    market_data.get('liquidityNum') or market_data.get('liquidity'),
                    market_data.get('enableOrderBook') or market_data.get('enable_order_book'),
                    market_data.get('acceptingOrders') or market_data.get('accepting_orders'),
                    market_data.get('negRisk') or market_data.get('neg_risk'),
                    market_data.get('negRiskMarketID') or market_data.get('neg_risk_market_id'),
                    market_data.get('umaBond') or market_data.get('uma_bond'),
                    market_data.get('umaReward') or market_data.get('uma_reward'),
                    self.parse_timestamp(market_data.get('umaEndDate') or market_data.get('uma_end_date')),
                    market_data.get('umaResolutionStatus') or market_data.get('uma_resolution_status'),
                    market_data.get('image'),
                    market_data.get('icon'),
                    market_data.get('submitted_by'),
                    category,
                    market_data.get('data_source'),
                    market_data.get('sport_type')
                )

                cursor.execute(market_sql, market_values)

                market_id = market_data.get('id')

                # æ’å…¥ç»“æœé€‰é¡¹
                self.insert_market_outcomes(cursor, market_id, market_data)

                # æ’å…¥äº‹ä»¶
                self.insert_market_events(cursor, market_id, market_data)

                # æ’å…¥åˆçº¦åœ°å€
                self.insert_contract_addresses(cursor, market_id, market_data)

                # æ’å…¥ä»£å¸ID
                self.insert_clob_token_ids(cursor, market_id, market_data)

                # æ’å…¥å¥–åŠ±
                self.insert_market_rewards(cursor, market_id, market_data)

                self.conn.commit()
                print(f"âœ… å¸‚åœº {market_id} æ•°æ®æ’å…¥æˆåŠŸ")

        except Exception as e:
            self.conn.rollback()
            print(f"âŒ æ’å…¥å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            raise

    def insert_market_outcomes(self, cursor, market_id, market_data):
        """æ’å…¥å¸‚åœºç»“æœé€‰é¡¹"""
        outcomes = market_data.get('outcomes', '[]')
        outcome_prices = market_data.get('outcomePrices', '[]')

        if isinstance(outcomes, str):
            outcomes = json.loads(outcomes)
        if isinstance(outcome_prices, str):
            outcome_prices = json.loads(outcome_prices)

        if outcomes:
            outcome_data = []
            for i, outcome in enumerate(outcomes):
                price = outcome_prices[i] if i < len(outcome_prices) else None
                outcome_data.append((market_id, outcome, price, i))

            execute_values(cursor,
                "INSERT INTO market_outcomes (market_id, outcome_text, outcome_price, outcome_index) VALUES %s",
                outcome_data)

    def insert_market_events(self, cursor, market_id, market_data):
        """æ’å…¥å¸‚åœºäº‹ä»¶"""
        events = market_data.get('events', [])
        if events:
            event_data = []
            for event in events:
                event_data.append((
                    market_id,
                    event.get('id'),
                    event.get('ticker'),
                    event.get('slug'),
                    event.get('title'),
                    event.get('description'),
                    self.parse_timestamp(event.get('startDate')),
                    self.parse_timestamp(event.get('endDate')),
                    self.parse_timestamp(event.get('createdAt')),
                    event.get('active', True),
                    event.get('closed', False),
                    event.get('archived', False),
                    event.get('volume'),
                    event.get('liquidity'),
                    event.get('commentCount') or event.get('comment_count')
                ))

            execute_values(cursor,
                """INSERT INTO market_events
                   (market_id, event_id, ticker, event_slug, title, event_description,
                    event_start_date, event_end_date, event_created_at, active, closed, archived,
                    volume, liquidity, comment_count) VALUES %s""",
                event_data)

    def insert_contract_addresses(self, cursor, market_id, market_data):
        """æ’å…¥åˆçº¦åœ°å€"""
        addresses = market_data.get('contract_addresses', {})
        if addresses:
            cursor.execute(
                """INSERT INTO contract_addresses
                   (market_id, conditional_tokens, clob_exchange, fee_module)
                   VALUES (%s, %s, %s, %s)""",
                (market_id,
                 addresses.get('conditional_tokens'),
                 addresses.get('clob_exchange'),
                 addresses.get('fee_module'))
            )

    def insert_clob_token_ids(self, cursor, market_id, market_data):
        """æ’å…¥CLOBä»£å¸ID"""
        token_ids = market_data.get('clob_token_ids', [])
        outcomes = market_data.get('outcomes', '[]')

        if isinstance(outcomes, str):
            outcomes = json.loads(outcomes)

        if token_ids:
            token_data = []
            for i, token_id in enumerate(token_ids):
                outcome_text = outcomes[i] if i < len(outcomes) else f"Option {i+1}"
                token_data.append((market_id, token_id, i, outcome_text))

            execute_values(cursor,
                "INSERT INTO clob_token_ids (market_id, token_id, token_index, outcome_text) VALUES %s",
                token_data)

    def insert_market_rewards(self, cursor, market_id, market_data):
        """æ’å…¥å¸‚åœºå¥–åŠ±"""
        rewards = market_data.get('clobRewards') or market_data.get('clob_rewards', [])
        if rewards:
            reward_data = []
            for reward in rewards:
                reward_data.append((
                    market_id,
                    reward.get('id'),
                    reward.get('assetAddress') or reward.get('asset_address'),
                    reward.get('rewardsAmount') or reward.get('rewards_amount'),
                    reward.get('rewardsDailyRate') or reward.get('rewards_daily_rate'),
                    reward.get('startDate') or reward.get('start_date'),
                    reward.get('endDate') or reward.get('end_date')
                ))

            execute_values(cursor,
                """INSERT INTO market_rewards
                   (market_id, reward_id, asset_address, rewards_amount,
                    rewards_daily_rate, start_date, end_date) VALUES %s""",
                reward_data)

    def insert_data_file_record(self, filename, file_path, category, total_markets):
        """æ’å…¥æ•°æ®æ–‡ä»¶è®°å½•"""
        try:
            with self.conn.cursor() as cursor:
                cursor.execute(
                    """INSERT INTO data_files
                       (filename, file_path, category, total_markets, status)
                       VALUES (%s, %s, %s, %s, 'completed')
                       ON CONFLICT (filename) DO UPDATE SET
                           processed_at = NOW(),
                           status = 'completed'""",
                    (filename, file_path, category, total_markets)
                )
                self.conn.commit()
        except Exception as e:
            print(f"âŒ æ’å…¥æ–‡ä»¶è®°å½•å¤±è´¥: {e}")

    def store_raw_json_data(self, file_path, data, category):
        """å­˜å‚¨åŸå§‹JSONæ•°æ®"""
        try:
            filename = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)

            # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³
            file_timestamp = None
            if '_2026' in filename:
                # æå–æ—¶é—´æˆ³éƒ¨åˆ†
                parts = filename.split('_2026')
                if len(parts) > 1:
                    timestamp_str = '2026' + parts[1].split('.')[0]
                    try:
                        file_timestamp = datetime.strptime(timestamp_str, '%Y%m%d%H%M%S')
                    except:
                        pass

            # å‡†å¤‡æ•°æ®
            metadata_json = json.dumps(data.get('metadata', {}), ensure_ascii=False)
            markets_json = json.dumps(data.get('markets', []), ensure_ascii=False)

            total_markets = data.get('metadata', {}).get('total_markets', 0)

            with self.conn.cursor() as cursor:
                cursor.execute(
                    """INSERT INTO raw_json_data
                       (filename, category, file_timestamp, total_markets,
                        metadata_json, markets_json, file_size_bytes)
                       VALUES (%s, %s, %s, %s, %s, %s, %s)
                       ON CONFLICT (filename, category) DO UPDATE SET
                           file_timestamp = EXCLUDED.file_timestamp,
                           total_markets = EXCLUDED.total_markets,
                           metadata_json = EXCLUDED.metadata_json,
                           markets_json = EXCLUDED.markets_json,
                           file_size_bytes = EXCLUDED.file_size_bytes,
                           last_updated = NOW()""",
                    (filename, category, file_timestamp, total_markets,
                     metadata_json, markets_json, file_size)
                )
                self.conn.commit()
                print(f"âœ… åŸå§‹JSONæ•°æ®å­˜å‚¨æˆåŠŸ: {filename} ({file_size} bytes)")

        except Exception as e:
            self.conn.rollback()
            print(f"âŒ å­˜å‚¨åŸå§‹JSONæ•°æ®å¤±è´¥: {e}")

    def import_file(self, file_path, category):
        """å¯¼å…¥å•ä¸ªæ–‡ä»¶"""
        print(f"\\nğŸ”„ å¼€å§‹å¯¼å…¥æ–‡ä»¶: {file_path}")

        # åŠ è½½æ•°æ®
        data = self.load_json_file(file_path)
        if not data:
            return False

        filename = os.path.basename(file_path)
        total_markets = data.get('metadata', {}).get('total_markets', 0)

        try:
            # 1. å­˜å‚¨åŸå§‹JSONæ•°æ®
            self.store_raw_json_data(file_path, data, category)

            # 2. å¯¼å…¥ç»“æ„åŒ–æ•°æ®
            markets_imported = 0
            for market_data in data.get('markets', []):
                self.insert_market(market_data, category)
                markets_imported += 1

            # 3. è®°å½•æ–‡ä»¶ä¿¡æ¯
            self.insert_data_file_record(filename, file_path, category, total_markets)

            print(f"âœ… æ–‡ä»¶ {filename} å¯¼å…¥å®Œæˆ:")
            print(f"   ğŸ“„ åŸå§‹JSONæ•°æ®: å·²å­˜å‚¨")
            print(f"   ğŸ›ï¸ ç»“æ„åŒ–æ•°æ®: {markets_imported} ä¸ªå¸‚åœº")
            print(f"   ğŸ“Š æ€»å¸‚åœºæ•°: {total_markets}")
            return True

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å¯¼å…¥å¤±è´¥: {e}")
            return False

    def import_all_files(self):
        """å¯¼å…¥æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        data_dir = Path('data')
        if not data_dir.exists():
            print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return

        # æ–‡ä»¶æ˜ å°„
        file_mapping = {
            'polymarket_markets_Sports_*.json': 'Sports',
            'polymarket_markets_Crypto_*.json': 'Crypto',
            'polymarket_markets_Politics_*.json': 'Politics'
        }

        imported_files = 0

        for pattern, category in file_mapping.items():
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            for file_path in data_dir.glob(pattern):
                if self.import_file(str(file_path), category):
                    imported_files += 1

        print(f"\\nğŸ‰ å¯¼å…¥å®Œæˆï¼Œå…±å¤„ç† {imported_files} ä¸ªæ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    importer = PolymarketDataImporter()

    try:
        # è¿æ¥æ•°æ®åº“
        importer.connect()

        # åˆ›å»ºè¡¨ç»“æ„
        if not importer.create_tables():
            return

        # å¯¼å…¥æ•°æ®
        importer.import_all_files()

    except Exception as e:
        print(f"âŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {e}")
    finally:
        importer.disconnect()

if __name__ == "__main__":
    main()
